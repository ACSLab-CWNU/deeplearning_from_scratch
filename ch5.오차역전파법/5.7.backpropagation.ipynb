{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "sys.path.append(os.pardir)\n",
        "from common.layers import *\n",
        "from common.gradient import numerical_gradient\n",
        "from dataset.mnist import load_mnist\n",
        "\n",
        "# 5.7.1 \uc2e0\uacbd\ub9dd \ud559\uc2b5\uc758 \uc804\uccb4 \uadf8\ub9bc\n",
        "\"\"\"\n",
        "(4.5\uc640 \ub3d9\uc77c)\n",
        "\uc804\uc81c\n",
        "\uc2e0\uacbd\ub9dd\uc5d0\ub294 \uc801\uc751 \uac00\ub2a5\ud55c \uac00\uc911\uce58\uc640 \ud3b8\ud5a5\uc774 \uc788\uace0, \uc774 \uac00\uc911\uce58\uc640 \ud3b8\ud5a5\uc744 \ud6c8\ub828 \ub370\uc774\ud130\uc5d0 \uc801\uc751\ud558\ub3c4\ub85d \uc870\uc815\ud558\ub294 \uacfc\uc815\uc744 '\ud559\uc2b5'\uc774\ub77c \ud55c\ub2e4.\n",
        "\uc2e0\uacbd\ub9dd \ud559\uc2b5\uc740 \ub2e4\uc74c\uacfc \uac19\uc774 4\ub2e8\uacc4\ub85c \uc218\ud589\ud55c\ub2e4.\n",
        "\n",
        "1\ub2e8\uacc4 - \ubbf8\ub2c8\ubc30\uce58\n",
        "\ud6c8\ub828 \ub370\uc774\ud130 \uc911 \uc77c\ubd80\ub97c \ubb34\uc791\uc704\ub85c \uac00\uc838\uc628\ub2e4. \uc774\ub807\uac8c \uc120\ubcc4\ud55c \ub370\uc774\ud130\ub97c \ubbf8\ub2c8\ubc30\uce58\ub77c \ud558\uba70,\n",
        "\uadf8 \ubbf8\ub2c8\ubc30\uce58\uc758 \uc190\uc2e4\ud568\uc218 \uac12\uc744 \uc904\uc774\ub294 \uac83\uc774 \ubaa9\ud45c\uc774\ub2e4.\n",
        "\n",
        "2\ub2e8\uacc4 - \uae30\uc6b8\uae30 \uc0b0\ucd9c\n",
        "\ubbf8\ub2c8\ubc30\uce58\uc758 \uc190\uc2e4 \ud568\uc218 \uac12\uc744 \uc904\uc774\uae30 \uc704\ud574 \uac01 \uac00\uc911\uce58 \ub9e4\uac1c\ubcc0\uc218\uc758 \uae30\uc6b8\uae30\ub97c \uad6c\ud55c\ub2e4.\n",
        "\uae30\uc6b8\uae30\ub294 \uc190\uc2e4 \ud568\uc218\uc758 \uac12\uc744 \uac00\uc7a5 \uc791\uac8c \ud558\ub294 \ubc29\ud5a5\uc744 \uc81c\uc2dc\ud55c\ub2e4.\n",
        "\n",
        "3\ub2e8\uacc4 - \ub9e4\uac1c\ubcc0\uc218 \uac31\uc2e0\n",
        "\uac00\uc911\uce58 \ub9e4\uac1c\ubcc0\uc218\ub97c \uae30\uc6b8\uae30 \ubc29\ud5a5\uc73c\ub85c \uc544\uc8fc \uc870\uae08 \uac31\uc2e0\ud55c\ub2e4.\n",
        "\n",
        "4\ub2e8\uacc4 - \ubc18\ubcf5\n",
        "1~3\ub2e8\uacc4\ub97c \ubc18\ubcf5\ud55c\ub2e4.\n",
        "\n",
        "\uc218\uce58 \ubbf8\ubd84\uacfc \uc624\ucc28\uc5ed\uc804\ud30c\ubc95\uc740 2\ub2e8\uacc4\uc5d0\uc11c \uc0ac\uc6a9\n",
        "\uc218\uce58 \ubbf8\ubd84\uc740 \uad6c\ud604\uc740 \uc27d\uc9c0\ub9cc \uacc4\uc0b0\uc774 \uc624\ub798\uac78\ub9bc\n",
        "\uc624\ucc28\uc5ed\uc804\ud30c\ubc95\uc744 \ud1b5\ud574 \uae30\uc6b8\uae30\ub97c \ud6a8\uc728\uc801\uc774\uace0 \ube60\ub974\uac8c \uad6c\ud560 \uc218 \uc788\uc74c\n",
        "\"\"\"\n",
        "\n",
        "# 5.7.2 \uc624\ucc28\uc5ed\uc804\ud30c\ubc95\uc744 \uc774\uc6a9\ud55c \uc2e0\uacbd\ub9dd \uad6c\ud604\ud558\uae30\n",
        "\"\"\"\n",
        "TwoLayerNet \ud074\ub798\uc2a4\ub85c \uad6c\ud604\n",
        " * \ud074\ub798\uc2a4\uc758 \uc778\uc2a4\ud134\uc2a4 \ubcc0\uc218\n",
        "params : \uc2e0\uacbd\ub9dd\uc758 \ub9e4\uac1c\ubcc0\uc218\ub97c \ubcf4\uad00\ud558\ub294 \ub515\uc154\ub108\ub9ac \ubcc0\uc218.\n",
        "        params['W1']\uc740 1\ubc88\uc9f8 \uce35\uc758 \uac00\uc911\uce58, params['b1']\uc740 1\ubc88\uc9f8 \uce35\uc758 \ud3b8\ud5a5.\n",
        "        params['W2']\uc740 2\ubc88\uc9f8 \uce35\uc758 \uac00\uc911\uce58, params['b2']\uc740 2\ubc88\uc9f8 \uce35\uc758 \ud3b8\ud5a5.\n",
        "layers : \uc2e0\uacbd\ub9dd\uc758 \uacc4\uce35\uc744 \ubcf4\uad00\ud558\ub294 \uc21c\uc11c\uac00 \uc788\ub294 \ub515\uc154\ub108\ub9ac \ubcc0\uc218\n",
        "        layers['Affine1'], layers['Relu1'], layers['Affine2']\uc640 \uac19\uc774\n",
        "        \uac01 \uacc4\uce35\uc744 \uc21c\uc11c\ub300\ub85c \uc720\uc9c0\n",
        "lastLayer : \uc2e0\uacbd\ub9dd\uc758 \ub9c8\uc9c0\ub9c9 \uacc4\uce35(\uc5ec\uae30\uc11c\ub294 SoftmaxWithLoss)\n",
        "\n",
        " * \ud074\ub798\uc2a4\uc758 \uba54\uc11c\ub4dc\n",
        "__init__(...) : \ucd08\uae30\ud654 \uc218\ud589\n",
        "predict(x) : \uc608\uce21(\ucd94\ub860)\uc744 \uc218\ud589\ud55c\ub2e4. x\ub294 \uc774\ubbf8\uc9c0 \ub370\uc774\ud130\n",
        "loss(x, t) : \uc190\uc2e4\ud568\uc218\uc758 \uac12\uc744 \uad6c\ud55c\ub2e4. x\ub294 \uc774\ubbf8\uc9c0 \ub370\uc774\ud130, t\ub294 \uc815\ub2f5 \ub808\uc774\ube14\n",
        "accuracy(x, t) : \uc815\ud655\ub3c4\ub97c \uad6c\ud55c\ub2e4.\n",
        "numerical_gradient(x, t) : \uac00\uc911\uce58 \ub9e4\uac1c\ubcc0\uc218\uc758 \uae30\uc6b8\uae30\ub97c \uc218\uce58 \ubbf8\ubd84\uc73c\ub85c \uad6c\ud568(\uc55e \uc7a5\uacfc \uac19\uc74c)\n",
        "gradient(x, t) : \uac00\uc911\uce58 \ub9e4\uac1c\ubcc0\uc218\uc758 \uae30\uc6b8\uae30\ub97c \uc624\ucc28\uc5ed\uc804\ud30c\ubc95\uc73c\ub85c \uad6c\ud568\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class TwoLayerNet:\n",
        "    def __init__(self, input_size, hidden_size, output_size,\n",
        "        weight_init_std=0.01):\n",
        "        # \uac00\uc911\uce58 \ucd08\uae30\ud654\n",
        "        self.params = {}\n",
        "        self.params['W1'] = weight_init_std * \\\n",
        "            np.random.randn(input_size, hidden_size)\n",
        "        self.params['b1'] = np.zeros(hidden_size)\n",
        "        self.params['W2'] = weight_init_std * \\\n",
        "            np.random.randn(hidden_size, output_size)\n",
        "        self.params['b2'] = np.zeros(output_size)\n",
        "\n",
        "        # \uacc4\uce35 \uc0dd\uc131\n",
        "        self.layers = OrderedDict()\n",
        "        self.layers['Affine1'] = \\\n",
        "            Affine(self.params['W1'], self.params['b1'])\n",
        "        self.layers['Relu1'] = Relu()\n",
        "        self.layers['Affine2'] = \\\n",
        "            Affine(self.params['W2'], self.params['b2'])\n",
        "        self.lastLayer = SoftmaxWithLoss()\n",
        "\n",
        "    def predict(self, x):\n",
        "        for layer in self.layers.values():\n",
        "            x = layer.forward(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    # x : \uc785\ub825 \ub370\uc774\ud130, t : \uc815\ub2f5 \ub808\uc774\ube14\n",
        "    def loss(self, x, t):\n",
        "        y = self.predict(x)\n",
        "        return self.lastLayer.forward(y, t)\n",
        "\n",
        "    def accuracy(self, x, t):\n",
        "        y = self.predict(x)\n",
        "        y = np.argmax(y, axis=1)\n",
        "        if t.ndim != 1:\n",
        "            t = np.argmax(t, axis=1)\n",
        "\n",
        "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
        "        return accuracy\n",
        "\n",
        "    def numerical_gradient(self, x, t):\n",
        "        loss_W = lambda W: self.loss(x, t)\n",
        "\n",
        "        grads = {}\n",
        "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
        "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
        "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
        "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
        "\n",
        "        return grads\n",
        "\n",
        "    def gradient(self, x, t):\n",
        "        # \uc21c\uc804\ud30c\n",
        "        self.loss(x, t)\n",
        "\n",
        "        # \uc5ed\uc804\ud30c\n",
        "        dout = 1\n",
        "        dout = self.lastLayer.backward(dout)\n",
        "\n",
        "        layers = list(self.layers.values())\n",
        "        layers.reverse()\n",
        "        for layer in layers:\n",
        "            dout = layer.backward(dout)\n",
        "\n",
        "        # \uacb0\uacfc \uc800\uc7a5\n",
        "        grads = {}\n",
        "        grads['W1'] = self.layers['Affine1'].dW\n",
        "        grads['b1'] = self.layers['Affine1'].db\n",
        "        grads['W2'] = self.layers['Affine2'].dW\n",
        "        grads['b2'] = self.layers['Affine2'].db\n",
        "\n",
        "        return grads\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\uc2e0\uacbd\ub9dd\uc758 \uacc4\uce35\uc744 \uc21c\uc11c\uac00 \uc788\ub294 \ub515\uc154\ub108\ub9ac\uc5d0\uc11c \ubcf4\uad00,\n",
        "\ub530\ub77c\uc11c \uc21c\uc804\ud30c\ub54c\ub294 \ucd94\uac00\ud55c \uc21c\uc11c\ub300\ub85c \uac01 \uacc4\uce35\uc758 forward()\ub97c \ud638\ucd9c\ud558\uae30\ub9cc \ud558\uba74 \ub41c\ub2e4.\n",
        "\uc5ed\uc804\ud30c\ub54c\ub294 \uacc4\uce35\uc744 \ubc18\ub300 \uc21c\uc11c\ub85c \ud638\ucd9c\ud558\uae30\ub9cc \ud558\uba74 \ub41c\ub2e4.\n",
        "\uc2e0\uacbd\ub9dd\uc758 \uad6c\uc131 \uc694\uc18c\ub97c \ubaa8\ub4c8\ud654\ud558\uc5ec \uacc4\uce35\uc73c\ub85c \uad6c\ud604\ud588\uae30 \ub54c\ubb38\uc5d0 \uad6c\ucd95\uc774 \uc26c\uc6cc\uc9c4\ub2e4.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# 5.7.3 \uc624\ucc28\uc5ed\uc804\ud30c\ubc95\uc73c\ub85c \uad6c\ud55c \uae30\uc6b8\uae30 \uac80\uc99d\ud558\uae30\n",
        "\"\"\"\n",
        "\uae30\uc6b8\uae30\ub97c \uad6c\ud558\ub294\ub370\ub294 \ub450 \uac00\uc9c0 \ubc29\ubc95\uc774 \uc788\ub2e4.\n",
        "1. \uc218\uce58 \ubbf8\ubd84 : \ub290\ub9ac\ub2e4. \uad6c\ud604\uc774 \uc27d\ub2e4.\n",
        "2. \ud574\uc11d\uc801\uc73c\ub85c \uc218\uc2dd\uc744 \ud480\uae30(\uc624\ucc28 \uc5ed\uc804\ud30c\ubc95) : \ube60\ub974\uc9c0\ub9cc \uc2e4\uc218\uac00 \uc788\uc744 \uc218 \uc788\ub2e4.\n",
        "\ub450 \uae30\uc6b8\uae30 \uacb0\uacfc\ub97c \ube44\uad50\ud574\uc11c \uc624\ucc28\uc5ed\uc804\ud30c\ubc95\uc744 \uc81c\ub300\ub85c \uad6c\ud604\ud588\ub294\uc9c0 \uac80\uc99d\ud55c\ub2e4.\n",
        "\uc774 \uc791\uc5c5\uc744 \uae30\uc6b8\uae30 \ud655\uc778gradient check\ub77c\uace0 \ud55c\ub2e4.\n",
        "\"\"\"\n",
        "if __name__ == '__main__':\n",
        "    # \ub370\uc774\ud130 \uc77d\uae30\n",
        "    (x_train, t_train), (x_test, t_test) = \\\n",
        "        load_mnist(normalize=True, one_hot_label=True)\n",
        "\n",
        "    network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
        "\n",
        "    x_batch = x_train[:3]\n",
        "    t_batch = t_train[:3]\n",
        "\n",
        "    grad_numerical = network.numerical_gradient(x_batch, t_batch)\n",
        "    grad_backprop = network.gradient(x_batch, t_batch)\n",
        "\n",
        "    # \uac01 \uac00\uc911\uce58\uc758 \ucc28\uc774\uc758 \uc808\ub313\uac12\uc744 \uad6c\ud55c \ud6c4, \uadf8 \uc808\ub313\uac12\ub4e4\uc758 \ud3c9\uade0\uc744 \ub0b8\ub2e4.\n",
        "    for key in grad_numerical.keys():\n",
        "        diff = np.average(np.abs(grad_backprop[key] - grad_numerical[key]))\n",
        "        print(key + \":\" + str(diff))\n",
        "        \"\"\"\n",
        "        W2:9.71260696544e-13\n",
        "        b2:1.20570232964e-10\n",
        "        W1:2.86152966578e-13\n",
        "        b1:1.19419626098e-12\n",
        "        \uc218\uce58 \ubbf8\ubd84\uacfc \uc624\ucc28\uc5ed\uc804\ud30c\ubc95\uc73c\ub85c \uad6c\ud55c \uae30\uc6b8\uae30\uc758 \ucc28\uc774\uac00 \ub9e4\uc6b0 \uc791\ub2e4.\n",
        "        \uc2e4\uc218 \uc5c6\uc774 \uad6c\ud604\ub418\uc5c8\uc744 \ud655\ub960\uc774 \ub192\ub2e4.\n",
        "        \uc815\ubc00\ub3c4\uac00 \uc720\ud55c\ud558\uae30 \ub54c\ubb38\uc5d0 \uc624\ucc28\uac00 0\uc774 \ub418\uc9c0\ub294 \uc54a\ub294\ub2e4.\n",
        "        \"\"\"\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}