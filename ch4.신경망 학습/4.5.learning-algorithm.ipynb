{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc804\uc81c\n",
        "\uc2e0\uacbd\ub9dd\uc5d0\ub294 \uc801\uc751 \uac00\ub2a5\ud55c \uac00\uc911\uce58\uc640 \ud3b8\ud5a5\uc774 \uc788\uace0, \uc774 \uac00\uc911\uce58\uc640 \ud3b8\ud5a5\uc744 \ud6c8\ub828 \ub370\uc774\ud130\uc5d0 \uc801\uc751\ud558\ub3c4\ub85d \uc870\uc815\ud558\ub294 \uacfc\uc815\uc744 '\ud559\uc2b5'\uc774\ub77c \ud55c\ub2e4.\n",
        "\uc2e0\uacbd\ub9dd \ud559\uc2b5\uc740 \ub2e4\uc74c\uacfc \uac19\uc774 4\ub2e8\uacc4\ub85c \uc218\ud589\ud55c\ub2e4.\n",
        "\n",
        "1\ub2e8\uacc4 - \ubbf8\ub2c8\ubc30\uce58\n",
        "\ud6c8\ub828 \ub370\uc774\ud130 \uc911 \uc77c\ubd80\ub97c \ubb34\uc791\uc704\ub85c \uac00\uc838\uc628\ub2e4. \uc774\ub807\uac8c \uc120\ubcc4\ud55c \ub370\uc774\ud130\ub97c \ubbf8\ub2c8\ubc30\uce58\ub77c \ud558\uba70,\n",
        "\uadf8 \ubbf8\ub2c8\ubc30\uce58\uc758 \uc190\uc2e4\ud568\uc218 \uac12\uc744 \uc904\uc774\ub294 \uac83\uc774 \ubaa9\ud45c\uc774\ub2e4.\n",
        "\n",
        "2\ub2e8\uacc4 - \uae30\uc6b8\uae30 \uc0b0\ucd9c\n",
        "\ubbf8\ub2c8\ubc30\uce58\uc758 \uc190\uc2e4 \ud568\uc218 \uac12\uc744 \uc904\uc774\uae30 \uc704\ud574 \uac01 \uac00\uc911\uce58 \ub9e4\uac1c\ubcc0\uc218\uc758 \uae30\uc6b8\uae30\ub97c \uad6c\ud55c\ub2e4.\n",
        "\uae30\uc6b8\uae30\ub294 \uc190\uc2e4 \ud568\uc218\uc758 \uac12\uc744 \uac00\uc7a5 \uc791\uac8c \ud558\ub294 \ubc29\ud5a5\uc744 \uc81c\uc2dc\ud55c\ub2e4.\n",
        "\n",
        "3\ub2e8\uacc4 - \ub9e4\uac1c\ubcc0\uc218 \uac31\uc2e0\n",
        "\uac00\uc911\uce58 \ub9e4\uac1c\ubcc0\uc218\ub97c \uae30\uc6b8\uae30 \ubc29\ud5a5\uc73c\ub85c \uc544\uc8fc \uc870\uae08 \uac31\uc2e0\ud55c\ub2e4.\n",
        "\n",
        "4\ub2e8\uacc4 - \ubc18\ubcf5\n",
        "1~3\ub2e8\uacc4\ub97c \ubc18\ubcf5\ud55c\ub2e4.\n",
        "\n",
        "\ub370\uc774\ud130\ub97c \ubb34\uc791\uc704\ub85c \uc120\uc815\ud558\uae30 \ub54c\ubb38\uc5d0 \ud655\ub960\uc801 \uacbd\uc0ac \ud558\uac15\ubc95stochastic gradient descent,\n",
        "SGD\ub77c\uace0 \ubd80\ub978\ub2e4.\n",
        "'''\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "sys.path.append(os.pardir)\n",
        "from common.functions import sigmoid, softmax, cross_entropy_error\n",
        "from common.gradient import numerical_gradient\n",
        "\n",
        "\n",
        "class TwoLayerNet:\n",
        "    \"\"\"\n",
        "    params : \uc2e0\uacbd\ub9dd\uc758 \ub9e4\uac1c\ubcc0\uc218\ub97c \ubcf4\uad00\ud558\ub294 \ub515\uc154\ub108\ub9ac \ubcc0\uc218.\n",
        "    params['W1']\uc740 1\ubc88\uc9f8 \uce35\uc758 \uac00\uc911\uce58, params['b1']\uc740 1\ubc88\uc9f8 \uce35\uc758 \ud3b8\ud5a5.\n",
        "    params['W2']\uc740 2\ubc88\uc9f8 \uce35\uc758 \uac00\uc911\uce58, params['b2']\uc740 2\ubc88\uc9f8 \uce35\uc758 \ud3b8\ud5a5.\n",
        "\n",
        "    grad : \uae30\uc6b8\uae30\ub97c \ubcf4\uad00\ud558\ub294 \ub515\uc154\ub108\ub9ac \ubcc0\uc218(numerical_gradient()\uc758 \ubc18\ud658\uac12)\n",
        "    grads['W1']\uc740 1\ubc88\uc9f8 \uce35\uc758 \uac00\uc911\uce58\uc758 \uae30\uc6b8\uae30, grads['b1']\uc740 1\ubc88\uc9f8 \uce35\uc758 \ud3b8\ud5a5\uc758 \uae30\uc6b8\uae30.\n",
        "    grads['W2']\uc740 2\ubc88\uc9f8 \uce35\uc758 \uac00\uc911\uce58\uc758 \uae30\uc6b8\uae30, grads['b2']\uc740 2\ubc88\uc9f8 \uce35\uc758 \ud3b8\ud5a5\uc758 \uae30\uc6b8\uae30.\n",
        "    \"\"\"\n",
        "    # \ucd08\uae30\ud654\ub97c \uc218\ud589\ud55c\ub2e4.\n",
        "    def __init__(self, input_size, hidden_size, output_size,\n",
        "                 weight_init_std=0.01):\n",
        "        # \uac00\uc911\uce58 \ucd08\uae30\ud654\n",
        "        self.params = {}\n",
        "        self.params['W1'] = weight_init_std * \\\n",
        "            np.random.randn(input_size, hidden_size)\n",
        "        self.params['b1'] = np.zeros(hidden_size)\n",
        "        self.params['W2'] = weight_init_std * \\\n",
        "            np.random.randn(hidden_size, output_size)\n",
        "        self.params['b2'] = np.zeros(output_size)\n",
        "\n",
        "    # \uc608\uce21(\ucd94\ub860)\uc744 \uc218\ud589\ud55c\ub2e4.\n",
        "    def predict(self, x):\n",
        "        W1, W2 = self.params['W1'], self.params['W2']\n",
        "        b1, b2 = self.params['b1'], self.params['b2']\n",
        "\n",
        "        a1 = np.dot(x, W1) + b1\n",
        "        z1 = sigmoid(a1)\n",
        "        a2 = np.dot(z1, W2) + b2\n",
        "        y = softmax(a2)\n",
        "\n",
        "        return y\n",
        "\n",
        "    # \uc190\uc2e4 \ud568\uc218\uc758 \uac12\uc744 \uad6c\ud55c\ub2e4.\n",
        "    # x : \uc785\ub825\ub370\uc774\ud130, t : \uc815\ub2f5 \ub808\uc774\ube14\n",
        "    def loss(self, x, t):\n",
        "        y = self.predict(x)\n",
        "\n",
        "        return cross_entropy_error(y, t)\n",
        "\n",
        "    # \uc815\ud655\ub3c4\ub97c \uad6c\ud55c\ub2e4.\n",
        "    def accuracy(self, x, t):\n",
        "        y = self.predict(x)\n",
        "        y = np.argmax(y, axis=1)\n",
        "        t = np.argmax(t, axis=1)\n",
        "\n",
        "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
        "        return accuracy\n",
        "\n",
        "    # \uac00\uc911\uce58 \ub9e4\uac1c\ubcc0\uc218\uc758 \uae30\uc6b8\uae30\ub97c \uad6c\ud55c\ub2e4.\n",
        "    def numerical_gradient(self, x, t):\n",
        "        loss_W = lambda W: self.loss(x, t)\n",
        "\n",
        "        grads = {}\n",
        "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
        "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
        "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
        "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
        "\n",
        "        return grads\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    net = TwoLayerNet(input_size=784, hidden_size=100, output_size=10)\n",
        "    print(net.params['W1'].shape)  # (784, 100)\n",
        "    print(net.params['b1'].shape)  # (100,)\n",
        "    print(net.params['W2'].shape)  # (100, 10)\n",
        "    print(net.params['b2'].shape)  # (10,)\n",
        "\n",
        "    x = np.random.rand(100, 784)  # \ub354\ubbf8 \uc785\ub825 \ub370\uc774\ud130(100\uc7a5 \ubd84\ub7c9)\n",
        "    t = np.random.rand(100, 10)   # \ub354\ubbf8 \uc815\ub2f5 \ub808\uc774\ube14(100\uc7a5 \ubd84\ub7c9)\n",
        "\n",
        "    grads = net.numerical_gradient(x, t)  # \uae30\uc6b8\uae30 \uacc4\uc0b0\n",
        "    # \uc8fc\uc758 : \uc2e4\ud589\ud558\ub294\ub370 \uc544\uc8fc \uc624\ub798\uac78\ub9bc\n",
        "    print(grads['W1'].shape)  # (784, 100)\n",
        "    print(grads['b1'].shape)  # (100,)\n",
        "    print(grads['W2'].shape)  # (100, 10)\n",
        "    print(grads['b2'].shape)  # (10,)"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}